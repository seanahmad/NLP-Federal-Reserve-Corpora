{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"3_FOMC_Analysis_Preprocess_Text.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"}},"cells":[{"cell_type":"markdown","metadata":{"id":"iF8T-njKaDYV"},"source":["# Predicting interest rates from Federal Reserve documents\r\n","## Preprocessing II (Vol. 3)\r\n","FE 690: Machine Learning in Finance \\\\\r\n","Author: Theo Dimitrasopoulos \\\\\r\n","Advisor: Zachary Feinstein \\\\"]},{"cell_type":"markdown","metadata":{"id":"LguxeVxOppvk"},"source":["## Clean Text Data"]},{"cell_type":"code","metadata":{"id":"X2MZzFxZw5pK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611442327845,"user_tz":300,"elapsed":174,"user":{"displayName":"Theo Dimitrasopoulos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRNhCMR9OSve5rpYHqQ5AxXHb4FT75fg51p-tfkA=s64","userId":"13959094896036405890"}},"outputId":"6da361f4-6b9c-4965-88c9-749cf6e55193"},"source":["import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","IN_COLAB"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"-z1LUHSetAze","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611442330383,"user_tz":300,"elapsed":1229,"user":{"displayName":"Theo Dimitrasopoulos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRNhCMR9OSve5rpYHqQ5AxXHb4FT75fg51p-tfkA=s64","userId":"13959094896036405890"}},"outputId":"48200ab6-2ddc-4f2f-c94e-6974f582ff84"},"source":["if IN_COLAB:\n","  from google.colab import drive\n","  drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yXYq5yyPsQdI"},"source":["if IN_COLAB:\n","  # Uninstall existing versions:\n","  !pip uninstall bs4==0.0.1 -y\n","  !pip uninstall textract==1.6.3 -y\n","  !pip uninstall numpy==1.19.4 -y\n","  !pip uninstall pandas==1.1.4 -y\n","  !pip uninstall requests==2.24.0 -y\n","  !pip uninstall tqdm==4.51.0 -y\n","  !pip uninstall nltk==3.5 -y\n","  !pip uninstall quandl==3.5.3 -y\n","  !pip uninstall scikit-plot==0.3.7 -y\n","  !pip uninstall seaborn==0.11.0 -y\n","  !pip uninstall sklearn==0.0 -y\n","  !pip uninstall torch==1.7.0 -y\n","  !pip uninstall transformers==3.5.0 -y\n","  !pip uninstall wordcloud==1.8.0 -y\n","  !pip uninstall xgboost==1.2.1 -y\n","\n","  # Install packages:\n","  !pip install bs4==0.0.1\n","  !pip install textract==1.6.3\n","  !pip install numpy==1.19.4\n","  !pip install pandas==1.1.4\n","  !pip install requests==2.24.0\n","  !pip install tqdm==4.51.0\n","  !pip install nltk==3.5\n","  !pip install quandl==3.5.3\n","  !pip install scikit-plot==0.3.7\n","  !pip install seaborn==0.11.0\n","  !pip install sklearn==0.0\n","  !pip install torch==1.7.0\n","  !pip install transformers==3.5.0\n","  !pip install wordcloud==1.8.0\n","  !pip install xgboost==1.2.1\n","  #os.kill(os.getpid(), 9)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1wbIp-dfq-Gl"},"source":["import pprint\n","pprint.pprint(sys.path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qRlw9hFgq-Go"},"source":["import numpy as np\n","import pandas as pd\n","import datetime as dt\n","import os\n","import codecs\n","import io\n","from lxml import etree\n","from dateutil.relativedelta import *\n","\n","import seaborn as sns; sns.set(style=\"darkgrid\")\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","import re\n","import pickle\n","from tqdm.notebook import tqdm\n","\n","import nltk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewhYU9NanwF1"},"source":["if IN_COLAB:\n","  employment_data_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/MarketData/Employment/'\n","  cpi_data_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/MarketData/CPI/'\n","  fed_rates_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/MarketData/FEDRates/'\n","  fx_rates_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/MarketData/FXRates/'\n","  gdp_data_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/MarketData/GDP/'\n","  ism_data_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/MarketData/ISM/'\n","  sales_data_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/MarketData/Sales/'\n","  treasury_data_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/MarketData/Treasury/'\n","  fomc_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/FOMC/'\n","  preprocessed_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/preprocessed/'\n","  train_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/train_data/'\n","  output_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/result/'\n","  keyword_lm_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/LoughranMcDonald/'\n","  glove_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/GloVe/'\n","  model_dir = '/content/drive/My Drive/Colab Notebooks/proj2/src/data/models/'\n","else:\n","  employment_data_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/MarketData/Employment/'\n","  cpi_data_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/MarketData/CPI/'\n","  fed_rates_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/MarketData/FEDRates/'\n","  fx_rates_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/MarketData/FXRates/'\n","  gdp_data_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/MarketData/GDP/'\n","  ism_data_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/MarketData/ISM/'\n","  sales_data_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/MarketData/Sales/'\n","  treasury_data_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/MarketData/Treasury/'\n","  fomc_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/FOMC/'\n","  preprocessed_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/preprocessed/'\n","  train_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/train_data/'\n","  output_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/result/'\n","  keyword_lm_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/LoughranMcDonald/'\n","  glove_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/GloVe/'\n","  model_dir = 'C:/Users/theon/GDrive/Colab Notebooks/proj2/src/data/models/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_l3dC4Bq-Gr"},"source":["# Set display preference (Optional)\n","plt.rcParams[\"figure.figsize\"] = (18,9)\n","plt.style.use('fivethirtyeight')\n","\n","pd.options.display.max_rows = 20\n","pd.options.display.max_seq_items = 50\n","pd.set_option('display.max_colwidth', 200)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"38WoOBYDppvk"},"source":["## Define Utility Functions"]},{"cell_type":"code","metadata":{"id":"NlN39maLppvk"},"source":["# Functions for map() or apply()\n","\n","def get_word_count(x):\n","    x = x.replace(\"[SECTION]\", \"\")\n","    return len(re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', x))\n","        \n","def get_rate_change(x):\n","    # If x is string, convert to datetime\n","    if type(x) is str:\n","        try:\n","            x = dt.datetime.strptime(x, '%Y-%m-%d')\n","        except:\n","            return None\n","\n","    if x in fomc_calendar.index:\n","        return fomc_calendar.loc[x]['RateDecision']\n","    else:        \n","        return None\n","\n","def get_rate(x):\n","    # If x is string, convert to datetime\n","    if type(x) is str:\n","        try:\n","            x = dt.datetime.strptime(x, '%Y-%m-%d')\n","        except:\n","            return None\n","\n","    if x in fomc_calendar.index:\n","        return fomc_calendar.loc[x]['Rate']\n","    else:        \n","        return None\n","\n","def get_next_meeting_date(x):\n","    # If x is string, convert to datetime\n","    if type(x) is str:\n","        try:\n","            x = dt.datetime.strptime(x, '%Y-%m-%d')\n","            print(type(x))\n","        except:\n","            return None\n","\n","    # Add two days to get the day after next\n","    x = x + dt.timedelta(days=2)\n","\n","    # Just in case, sort fomc_calendar from older to newer\n","    fomc_calendar.sort_index(ascending=True, inplace=True)\n","\n","    if fomc_calendar['date'].iloc[0] > x:\n","        # If the date is older than the first FOMC Meeting, do not return any date.\n","        return None\n","    else:\n","        for i in range(len(fomc_calendar)):\n","            if x < fomc_calendar['date'].iloc[i]:\n","                return fomc_calendar['date'].iloc[i]\n","        # If x is greater than the newest FOMC meeting date, do not return any date.\n","        return None\n","\n","def get_chairperson(x):\n","    # If x is string, convert to datetime\n","    if type(x) is str:\n","        try:\n","            x = dt.datetime.strftime(x, '%Y-%m-%d')\n","            print(type(x))\n","        except:\n","            return None\n","\n","    chairperson = chairpersons.loc[chairpersons['FromDate'] <= x].loc[x <= chairpersons['ToDate']]\n","    return list(chairperson.FirstName)[0] + \" \" + list(chairperson.Surname)[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HK1xjz3Wppvk"},"source":["def reorganize_df(df, doc_type):\n","    if doc_type in ('statement', 'minutes', 'press_conference', 'meeting_script'):\n","        is_meeting_doc = True\n","    elif doc_type in ('speech', 'testimony'):\n","        is_meeting_doc = False\n","    else:\n","        print(\"Invalid doc_type [{}] is given!\".format(doc_type))\n","        return None\n","\n","    dict = {\n","        'type': doc_type,\n","        'date': df['date'],\n","        'title': df['title'],\n","        'speaker': df['speaker'],\n","        'word_count': df['contents'].map(get_word_count),\n","        'decision': df['date'].map(lambda x: get_rate_change(x) if is_meeting_doc else None),\n","        'rate': df['date'].map(lambda x: get_rate(x) if is_meeting_doc else None),\n","        'next_meeting': df['date'].map(get_next_meeting_date),\n","        'next_decision': df['date'].map(get_next_meeting_date).map(get_rate_change),\n","        'next_rate': df['date'].map(get_next_meeting_date).map(get_rate),        \n","        'text': df['contents'].map(lambda x: x.replace('\\n','').replace('\\r','').strip()),\n","        'text_sections': df['contents'].map(lambda x: x.replace('\\n','').replace('\\r','').strip().split(\"[SECTION]\")),\n","        'org_text': df['contents']\n","    }\n","\n","    new_df = pd.DataFrame(dict)\n","    new_df['decision'] = new_df['decision'].astype('Int8')\n","    new_df['next_decision'] = new_df['next_decision'].astype('Int8')\n","    print(\"No rate decision found: \", new_df['decision'].isnull().sum())\n","    print(\"Shape of the dataframe: \", new_df.shape)\n","    #new_df.dropna(subset=['decision'], axis=0, inplace=True)\n","    return new_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBxAsOY6ppvk"},"source":["# Split functions to process long text in machine learning based NLP\n","\n","def get_split(text, split_len=200, overlap=50):\n","    l_total = []\n","    words = re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', text)\n","\n","    if len(words) < split_len:\n","        n = 1\n","    else:\n","        n = (len(words) - overlap) // (split_len - overlap) + 1\n","\n","    for i in range(n):\n","        l_parcial = words[(split_len - overlap) * i: (split_len - overlap) * i + split_len]\n","        l_total.append(\" \".join(l_parcial))\n","    return l_total\n","\n","def get_split_df(df, split_len=200, overlap=50):\n","    split_data_list = []\n","\n","    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n","        #print(\"Original Word Count: \", row['word_count'])\n","        text_list = get_split(row[\"text\"], split_len, overlap)\n","        for text in text_list:\n","            row['text'] = text\n","            #print(len(re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', text)))\n","            row['word_count'] = len(re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', text))\n","            split_data_list.append(list(row))\n","\n","    split_df = pd.DataFrame(split_data_list, columns=df.columns)\n","    print(split_df)\n","    #split_df['decision'] = split_df['decision'].astype('Int8')\n","    #split_df['next_decision'] = split_df['next_decision'].astype('Int8')\n","\n","    return split_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SDGFbQ7ppvk"},"source":["def remove_short_section(df, min_words=50):\n","    '''\n","    Using 'text_sections' of the given dataframe, remove sections having less than min_words.\n","    It concatinate sections with a space, which exceeds min_words and update 'text'.\n","    As a fallback, keep a text which concatinates sections having more than 20 words and use it\n","     if there is no section having more than min_words.\n","    If there is no sections having more than 20 words, remove the row.\n","    '''\n","    new_df = df.copy()\n","    new_text_list = []\n","    new_text_section_list = []\n","    new_wc_list = []\n","\n","    for i, row in tqdm(new_df.iterrows(), total=new_df.shape[0]):\n","        new_text = \"\"\n","        bk_text = \"\"\n","        new_text_section = []\n","        bk_text_section = []\n","\n","        for section in row['text_sections']:\n","            num_words = len(re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', section))\n","            if num_words > min_words:\n","                new_text += \" \" + section\n","                new_text_section.append(section)\n","            elif num_words > 20:\n","                bk_text += \" \" + section\n","                bk_text_section.append(section)\n","\n","        new_text = new_text.strip()\n","        bk_text = bk_text.strip()\n","\n","        if len(new_text) > 0:\n","            new_text_list.append(new_text)\n","            new_text_section_list.append(new_text_section)\n","        elif len(bk_text) > 0:\n","            new_text_list.append(bk_text)\n","            new_text_section_list.append(bk_text_section)\n","        else:\n","            new_text_list.append(\"\")\n","            new_text_section_list.append(\"\")\n","\n","        # Update the word count\n","        new_wc_list.append(len(re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', new_text_list[-1])))\n","\n","    new_df['text'] = new_text_list\n","    new_df['word_count'] = new_wc_list\n","\n","    return new_df.loc[new_df['word_count'] > 0]\n","\n","def remove_short_nokeyword(df, keywords = ['rate', 'rates', 'federal fund', 'outlook', 'forecast', 'employ', 'economy'], min_times=2, min_words=50):\n","    '''\n","    Drop sections which do not have any one of keywords for min_times times\n","     before applying remove_short_section()\n","    '''\n","    new_df = df.copy()\n","    new_section_list = []\n","\n","    for i, row in tqdm(new_df.iterrows(), total=new_df.shape[0]):\n","        new_section = []\n","\n","        for section in row['text_sections']:\n","            if len(set(section.split()).intersection(keywords)) >= min_times:\n","                new_section.append(section)\n","\n","        new_section_list.append(new_section)\n","\n","    new_df['text_sections'] = new_section_list\n","\n","    return remove_short_section(new_df, min_words=min_words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OCFUvmVPppvk"},"source":["## Load Data"]},{"cell_type":"markdown","metadata":{"id":"KwLkz7K5ppvk"},"source":["### Chairpersons"]},{"cell_type":"code","metadata":{"id":"oA0Rm-3Rppvk"},"source":["# FOMC Chairperson's list\n","chairpersons = pd.DataFrame(\n","    data=[[\"Volcker\", \"Paul\", dt.datetime(1979,8,6), dt.datetime(1987,8,10)],\n","          [\"Greenspan\", \"Alan\", dt.datetime(1987,8,11), dt.datetime(2006,1,31)], \n","          [\"Bernanke\", \"Ben\", dt.datetime(2006,2,1), dt.datetime(2014,1,31)], \n","          [\"Yellen\", \"Janet\", dt.datetime(2014,2,3), dt.datetime(2018,2,3)],\n","          [\"Powell\", \"Jerome\", dt.datetime(2018,2,5), dt.datetime(2022,2,5)]],\n","    columns=[\"Surname\", \"FirstName\", \"FromDate\", \"ToDate\"])\n","chairpersons"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgYzQBsAppvk"},"source":["### Load Calendar"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"2KotRmYmq-HB"},"source":["file = open(fomc_dir + 'fomc_calendar.pickle', 'rb')\n","fomc_calendar = pickle.load(file)\n","file.close()\n","\n","print(type(fomc_calendar))\n","fomc_calendar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ut2ulVJZq-HE"},"source":["# #Check calendar\n","#fomc_calendar.loc[fomc_calendar['date'] >= dt.datetime(1998, 1, 27)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"91rDi3_9ppvo"},"source":["### Statement"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"1_58pBdJppvo"},"source":["file = open(fomc_dir + 'statement.pickle', 'rb')\n","statement_df = pickle.load(file)\n","file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTlE89nuppvo"},"source":["# Sample Contents - the 2nd last\n","print(statement_df['contents'].iloc[-1])\n","statement_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z23R9_Kuppvo"},"source":["### Meeting Minutes"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"f-DUDnhkppvo"},"source":["file = open(fomc_dir + 'minutes.pickle', 'rb')\n","minutes_df = pickle.load(file)\n","file.close()\n","\n","print(minutes_df.shape)\n","minutes_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OweUEZ1ppvo"},"source":["# Sample Contents - the 2nd last\n","print(minutes_df['contents'].iloc[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ngF9VPdvppvo"},"source":["### Meeting Transcripts"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"sc_eaXYJppvo"},"source":["file = open(fomc_dir + 'meeting_script.pickle', 'rb')\n","meeting_script_df = pickle.load(file)\n","file.close()\n","\n","print(meeting_script_df.shape)\n","meeting_script_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnYP0zEXppvo"},"source":["# Sample Contents - the 2nd last\n","print(meeting_script_df['contents'].iloc[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mDH2EXrmppvp"},"source":["### Press Conference Transcripts"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"kss0o1Hgppvp"},"source":["file = open(fomc_dir + 'press_conference.pickle', 'rb')\n","presconf_script_df = pickle.load(file)\n","file.close()\n","\n","print(presconf_script_df.shape)\n","presconf_script_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLyPNJEJppvp"},"source":["# Sample Contents - the 2nd last\n","print(presconf_script_df['contents'].iloc[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SscoJ7pXppvp"},"source":["### Speech"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"NGG932Meppvp"},"source":["file = open(fomc_dir + 'speech.pickle', 'rb')\n","speech_df = pickle.load(file)\n","file.close()\n","\n","print(speech_df.shape)\n","speech_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SgyoUoIVppvp"},"source":["# Sample Contents - the 2nd last\n","print(speech_df['contents'].iloc[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YN4F_U08ppvp"},"source":["### Testimony"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"9r0s-owjppvp"},"source":["file = open(fomc_dir + 'testimony.pickle', 'rb')\n","testimony_df = pickle.load(file)\n","file.close()\n","\n","print(testimony_df.shape)\n","testimony_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8W3fxmSCppvp"},"source":["# Sample Contents - the 2nd last\n","print(testimony_df['contents'].iloc[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nz5unLTMppvp"},"source":["### Statements"]},{"cell_type":"code","metadata":{"id":"RSDfSKK3ppvp"},"source":["statement_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6BmtYlkJppvp"},"source":["### Add Quantitative Easing as a Lower event"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"3IK8x11oppvp"},"source":["# Add When QE was first announced on 2008-11-25. No statemenet on that day.\n","\n","if statement_df.loc[statement_df['date'] == dt.datetime.strptime('2008-11-25', '%Y-%m-%d')].shape[0] == 0:\n","    qe_text = \"The Federal Reserve announced on Tuesday that it will initiate a program \"\\\n","              \"to purchase the direct obligations of housing-related government-sponsored \"\\\n","              \"enterprises (GSEs)--Fannie Mae, Freddie Mac, and the Federal Home Loan Banks \"\\\n","              \"--and mortgage-backed securities (MBS) backed by Fannie Mae, Freddie Mac, \"\\\n","              \"and Ginnie Mae.  Spreads of rates on GSE debt and on GSE-guaranteed mortgages \"\\\n","              \"have widened appreciably of late.  This action is being taken to reduce the cost \"\\\n","              \"and increase the availability of credit for the purchase of houses, which in turn \"\\\n","              \"should support housing markets and foster improved conditions in financial markets \"\\\n","              \"more generally. Purchases of up to $100 billion in GSE direct obligations under \"\\\n","              \"the program will be conducted with the Federal Reserve's primary dealers through \"\\\n","              \"a series of competitive auctions and will begin next week.  Purchases of up to \"\\\n","              \"$500 billion in MBS will be conducted by asset managers selected via a competitive \"\\\n","              \"process with a goal of beginning these purchases before year-end.  \"\\\n","              \"Purchases of both direct obligations and MBS are expected to take place over \"\\\n","              \"several quarters.  Further information regarding the operational details of this \"\\\n","              \"program will be provided after consultation with market participants.\"\n","    statement_df = statement_df.append(\n","        pd.Series([dt.datetime.strptime('2008-11-25', '%Y-%m-%d'), qe_text, 'Ben Bernanke', 'FOMC statement'], index=statement_df.columns),\n","        ignore_index=True\n","    )\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ep_XUZbbppvp"},"source":["### Process the dataframe"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"WPOApTdJppvp"},"source":["# Reorganize the dataframe\n","proc_statement_df = reorganize_df(statement_df, 'statement')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A56IpgjRppvp"},"source":["# Check the returned dataframe\n","proc_statement_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"F3_W_HYPppvq"},"source":["# Check which row does not have rate\n","proc_statement_df.loc[proc_statement_df['rate'].isnull()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfCdjY2Cppvq"},"source":["x = dt.datetime.strptime('2019-01-01', '%Y-%m-%d')\n","fomc_calendar.loc[fomc_calendar['date'].iloc[:] > x]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"mONHmrfXppvq"},"source":["# Remove sections having less than 50 words because those are unlikely to contain meaningful sentences.\n","proc_statement_df = remove_short_section(proc_statement_df, min_words=50)\n","proc_statement_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uco-LROeppvq"},"source":["plt.figure(figsize=(10,5))\n","sns.distplot(proc_statement_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5775BYtgppvq"},"source":["### Split contents to max 200 words"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"oZOSFAsvppvq"},"source":["split_statement_df = get_split_df(proc_statement_df)\n","split_statement_df.tail(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"65krMo3fppvq"},"source":["### Filter out by keywords"]},{"cell_type":"code","metadata":{"id":"OLy8cGDNppvq"},"source":["# Keep sections having keywords and long enough\n","keyword_statement_df = remove_short_nokeyword(proc_statement_df)\n","keyword_statement_df.reset_index(drop=True, inplace=True)\n","print(keyword_statement_df.shape)\n","keyword_statement_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kIUcoe7Xppvq"},"source":["# Drop text during the process to reduce the output size\n","proc_statement_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","split_statement_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","keyword_statement_df.drop(columns=['text_sections', 'org_text'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JoP5zJ-7ppvq"},"source":["### Minutes"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"SxtRe74Kppvq"},"source":["minutes_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"nCATJ7hnppvq"},"source":["# Reorganize the dataframe\n","proc_minutes_df = reorganize_df(minutes_df, 'minutes')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9xrmo_xmppvq"},"source":["# Check the returned dataframe\n","proc_minutes_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GwqiTqi6ppvq"},"source":["# Check which row does not have rate\n","proc_minutes_df.loc[proc_minutes_df['rate'].isnull()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRlB5lhrppvq"},"source":["plt.figure(figsize=(10,5))\n","sns.distplot(proc_minutes_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9czr_zMppvq"},"source":["# Check which row does not have rate\n","proc_minutes_df.loc[proc_minutes_df['rate'].isnull()]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OdVFjyBoppvq"},"source":["Meeting minutes includes various topics, so it makes sense to extract relevant sections. <br />\n","Check some common sections."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"2P_RoGTuppvq"},"source":["# Check what kind of sections are in common\n","\n","a = minutes_df.contents.str.lower().str.count('staff economic outlook')\n","b = minutes_df.contents.str.lower().str.count('developments in financial markets')\n","c = minutes_df.contents.str.lower().str.count('staff review of the economic situation')\n","d = minutes_df.contents.str.lower().str.count('staff review of the financial situation')\n","e = minutes_df.contents.str.lower().str.count('participants\\' views on current condition')\n","f = minutes_df.contents.str.lower().str.count('committee policy action')\n","g = minutes_df.contents.str.lower().str.count('voting for this action')\n","h = minutes_df.contents.str.lower().str.count('federal fund')\n","\n","pd.options.display.max_rows = 300\n","pd.DataFrame({'date': minutes_df['date'], 'a': a, 'b':b, 'c':c, 'd':d, 'e':e, 'f':f, 'g':g, 'h':h})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXvOxK2Qppvq"},"source":["pd.options.display.max_rows = 20"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PcjQYfEMppvq"},"source":["Sections are added from time to time. For example, quarterly economic forcast started in 2009. Leave manually handling those for now, take another approach to filter sentenses by length and key words here."]},{"cell_type":"code","metadata":{"id":"8n55_-oSppvq"},"source":["proc_minutes_df = remove_short_section(proc_minutes_df, min_words=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_9vDhevIppvq"},"source":["### Split contents to max 200 words"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"AmMOphaDppvr"},"source":["split_minutes_df = get_split_df(proc_minutes_df)\n","print(split_minutes_df.shape)\n","split_minutes_df.tail(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"34ioC8uDppvr"},"source":["### Filter out by keywords"]},{"cell_type":"code","metadata":{"id":"0-H33Nifppvr"},"source":["# Keep sections having keywords and long enough\n","keyword_minutes_df = remove_short_nokeyword(proc_minutes_df)\n","keyword_minutes_df.reset_index(drop=True, inplace=True)\n","print(keyword_minutes_df.shape)\n","keyword_minutes_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RVoeSIT7ppvr"},"source":["plt.figure(figsize=(10,5))\n","sns.distplot(proc_minutes_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rLt49JdYppvr"},"source":["# Drop text during the process to reduce the output size\n","proc_minutes_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","split_minutes_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","keyword_minutes_df.drop(columns=['text_sections', 'org_text'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WST9bN8xppvr"},"source":["## Press Conference Script"]},{"cell_type":"code","metadata":{"id":"Wb_Lo-LRppvr"},"source":["# Sample\n","print(presconf_script_df['contents'][2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"EdC5lTh1ppvr"},"source":["# Reorganize the dataframe\n","proc_presconf_script_df = reorganize_df(presconf_script_df, 'press_conference')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cx8hTwm0ppvr"},"source":["# Check the returned dataframe\n","proc_presconf_script_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PxU9q6zLppvr"},"source":["# Check which row does not have rate\n","proc_presconf_script_df.loc[proc_presconf_script_df['rate'].isnull()]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1_gGMILZppvr"},"source":["### Split by speakers\n","Scripts contain words from different people, so split by the speaker"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"evJl1K1Xppvr"},"source":["script_data_list = []\n","\n","for i, row in tqdm(proc_presconf_script_df.iterrows()):\n","    for text in row[\"text_sections\"]:\n","        match = re.findall(r'(^[A-Za-zŞ. ]*[A-Z]{3}).\\d? (.*)', text)\n","        if len(match) == 0:\n","            match = re.findall(r'(^[A-Za-zŞ. ]*[A-Z]{3}).\\d(.*)', text)\n","            if len(match) == 0:\n","                print(\"not matched: \", text)\n","                print(row['date'])\n","                print()\n","        if len(match) == 1:\n","            speaker, text = match[0]\n","            row['speaker'] = speaker\n","            row['text'] = text\n","            row['word_count'] = len(re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', text))\n","            script_data_list.append(list(row))\n","\n","col_name = proc_presconf_script_df.columns\n","\n","presconf_script_speaker_df = pd.DataFrame(script_data_list, columns = col_name)\n","print(presconf_script_speaker_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9knNkwlppvr"},"source":["# Filter by the word count\n","#presconf_script_speaker_df = presconf_script_speaker_df.loc[presconf_script_speaker_df['word_count'] >= 50]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"59HFpPRvppvr"},"source":["print(presconf_script_speaker_df.shape)\n","sns.distplot(presconf_script_speaker_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PnIIAubxppvr"},"source":["# Filter to have only chairperson's speak\n","\n","tmp_list = []\n","for i, row in presconf_script_speaker_df.iterrows():\n","    chairperson = get_chairperson(row['date'])\n","    if chairperson.lower().split()[-1] in row['speaker'].lower():\n","        row['speaker'] = chairperson\n","        tmp_list.append(list(row))\n","\n","col_names = presconf_script_speaker_df.columns\n","presconf_script_chair_df = pd.DataFrame(data=tmp_list, columns=col_names)\n","presconf_script_chair_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"UzPcFoSSppvr"},"source":["# Combine scripts of the same speaker for the same day.\n","tmp_date = ''\n","tmp_speaker = ''\n","tmp_data = []\n","\n","print('Before: ', presconf_script_chair_df.shape)\n","\n","for i, row in tqdm(presconf_script_chair_df.iterrows()):\n","    if (row['date'] == tmp_date) and (row['speaker'] == tmp_speaker):\n","        tmp_data[-1]['text'] += row['text']\n","        tmp_data[-1]['word_count'] += row['word_count']\n","        tmp_data[-1]['text_sections'].append(row['text'])\n","    else:\n","        tmp_date = row['date']\n","        tmp_speaker = row['speaker']\n","        row['text_sections'] = [row['text']]\n","        tmp_data.append(row)\n","\n","presconf_script_chair_day_df = pd.DataFrame(tmp_data)\n","\n","print('After', presconf_script_chair_day_df.shape)\n","presconf_script_chair_day_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iiOg8Dappvr"},"source":["sns.distplot(list(presconf_script_chair_day_df['word_count']), bins=50, kde=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1aywAEtUppvr"},"source":["# # Check text\n","# print(presconf_script_chair_day_df['text'][0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KEbLPnJIppvr"},"source":["### Split contents to max 200 words"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"3X6J8y-Vppvr"},"source":["presconf_script_split_df = get_split_df(presconf_script_chair_day_df)\n","print(presconf_script_split_df.shape)\n","presconf_script_split_df.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-9IlLRhppvr"},"source":["### Filter out by keywords"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"bSMQx6XIppvr"},"source":["# Keep sections having keywords and long enough\n","presconf_script_keyword_df = remove_short_nokeyword(presconf_script_chair_day_df)\n","presconf_script_keyword_df.reset_index(drop=True, inplace=True)\n","print(presconf_script_keyword_df.shape)\n","presconf_script_keyword_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEmMVvtjppvr"},"source":["sns.distplot(list(presconf_script_keyword_df['word_count']), bins=50, kde=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFvxqNSOppvs"},"source":["# Drop text during the process to reduce the output size\n","presconf_script_chair_day_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","presconf_script_split_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","presconf_script_keyword_df.drop(columns=['text_sections', 'org_text'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZrzyFJcXppvs"},"source":["## Meeting Script"]},{"cell_type":"code","metadata":{"id":"dTwyrlFvKBBm"},"source":["meeting_script_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWBNskaSppvs"},"source":["# Reorganize the dataframe\n","proc_meeting_script_df = reorganize_df(meeting_script_df, 'meeting_script')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b2ZlcL0ppvs"},"source":["# Sample\n","print(meeting_script_df['contents'][2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yzhsothUppvs"},"source":["# Check the returned dataframe\n","proc_meeting_script_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkLxc_NYppvs"},"source":["# Check which row does not have rate\n","proc_meeting_script_df.loc[proc_meeting_script_df['rate'].isnull()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7MWX0fDppvs"},"source":["print(proc_meeting_script_df.shape)\n","sns.distplot(proc_meeting_script_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vaaLxyOEppvs"},"source":["### Split by speakers\n","Scripts contain words from different people, so split by the speaker"]},{"cell_type":"code","metadata":{"id":"rvIeWH7cppvs"},"source":["script_data_list = []\n","\n","for i, row in tqdm(proc_meeting_script_df.iterrows()):\n","    for text in row[\"text_sections\"]:\n","        match = re.findall(r'(^[A-Za-zŞ. ]*[A-Z]{3}).\\d? (.*)', text)\n","        if len(match) == 0:\n","            match = re.findall(r'(^[A-Za-zŞ. ]*[A-Z]{3}).\\d(.*)', text)\n","            if len(match) == 0:\n","                print(\"not matched: \", text)\n","                print(row['date'])\n","                print()\n","        if len(match) == 1:\n","            speaker, text = match[0]\n","            row['speaker'] = speaker\n","            row['text'] = text\n","            row['word_count'] = len(re.findall(r'\\b([a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', text))\n","            script_data_list.append(list(row))\n","\n","col_name = proc_meeting_script_df.columns\n","\n","meeting_script_speaker_df = pd.DataFrame(script_data_list, columns = col_name)\n","meeting_script_speaker_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tVJ6iIYFppvs"},"source":["Some are not matching the defined patterns but those unmatched ones do not look importnant. Thus ignore them here."]},{"cell_type":"code","metadata":{"id":"CKyY9xQkppvs"},"source":["# Filter by word count having 20 or more.\n","print(\"Before: \", meeting_script_speaker_df.shape)\n","meeting_script_speaker_df = meeting_script_speaker_df.loc[meeting_script_speaker_df['word_count'] >= 20]\n","print(\"After: \", meeting_script_speaker_df.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7RgN-tOppvs"},"source":["sns.distplot(meeting_script_speaker_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4JSJRsqppvs"},"source":["# Combine scripts for the same day.\n","meeting_script_speaker_df = meeting_script_speaker_df['text'].apply('[SECTION]'.join).reset_index()\n","meeting_script_speaker_df['text_sections'] = meeting_script_speaker_df['text'].map(lambda x: x.split(\"[SECTION]\"))\n","meeting_script_speaker_df['text'] = meeting_script_speaker_df['text'].map(lambda x: x.replace(\"[SECTION]\", \"\"))\n","meeting_script_speaker_df['word_count'] = meeting_script_speaker_df['text'].map(get_word_count)\n","meeting_script_speaker_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7j_giHnRppvs"},"source":["sns.distplot(meeting_script_speaker_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kl74OZH7ppvs"},"source":["### Split contents to max 200 words"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"9TjbZYA5ppvs"},"source":["meeting_script_split_df = get_split_df(meeting_script_speaker_df)\n","print(meeting_script_split_df.shape)\n","meeting_script_split_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5EDiTSjippvs"},"source":["### Filter out by keywords"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"a_adja4kppvs"},"source":["# Keep sections having keywords and long enough\n","meeting_script_keyword_df = remove_short_nokeyword(meeting_script_speaker_df)\n","meeting_script_keyword_df.reset_index(drop=False, inplace=True)\n","print(meeting_script_keyword_df.shape)\n","meeting_script_keyword_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaCUtsesppvs"},"source":["# Drop text during the process to reduce the output size\n","meeting_script_speaker_df.drop(columns=['text_sections'], inplace=True)\n","meeting_script_split_df.drop(columns=['text_sections'], inplace=True)\n","meeting_script_keyword_df.drop(columns=['text_sections'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SagN3laMppvs"},"source":["## Speech"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"0fmM4xqvppvs"},"source":["# Reorganize the dataframe\n","proc_speech_df = reorganize_df(speech_df, 'speech')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5cBHha8ppvt"},"source":["# Check the returned dataframe\n","# Note that rate and decision are not applicable because speech is not at FOMC meeting\n","proc_speech_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"DpJnPHJ2ppvt"},"source":["print(proc_speech_df.shape)\n","sns.distplot(proc_speech_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UU91GSgtppvt"},"source":["# Check records where speaker is null\n","proc_speech_df['speaker'].isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNmpVPyKppvt"},"source":["# Remove sections having less than 50 words because those are unlikely to contain meaningful sentences.\n","proc_speech_df = remove_short_section(proc_speech_df, min_words=50)\n","proc_speech_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"apVxtoqfppvt"},"source":["# Extract Chairperson's speech\n","tmp_list = []\n","for i, row in proc_speech_df.iterrows():\n","    chairperson = get_chairperson(row['date'])\n","    if chairperson.lower().split()[-1] in row['speaker'].lower():\n","        row['speaker'] = chairperson\n","        tmp_list.append(list(row))\n","\n","col_names = proc_speech_df.columns\n","speech_chair_df = pd.DataFrame(data=tmp_list, columns=col_names)\n","\n","print(speech_chair_df.shape)\n","speech_chair_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QNlz_SbYppvt"},"source":["### Split contents to max 200 words"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"vWVPJmgFppvt"},"source":["speech_split_df = get_split_df(speech_chair_df)\n","speech_split_df.reset_index(drop=True, inplace=True)\n","print(speech_split_df.shape)\n","speech_split_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UR0_cZE1ppvt"},"source":["### Filter out by keyword"]},{"cell_type":"code","metadata":{"id":"wIsZhzpCppvt"},"source":["# Keep sections having keywords and long enough\n","speech_keyword_df = remove_short_nokeyword(speech_chair_df)\n","speech_keyword_df.reset_index(drop=True, inplace=True)\n","print(speech_keyword_df.shape)\n","speech_keyword_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUdJgEtxppvt"},"source":["# Drop text_sections\n","speech_chair_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","speech_split_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","speech_keyword_df.drop(columns=['text_sections', 'org_text'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6qhhY7Udppvt"},"source":["## Testimony"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"LKdic3UAppvt"},"source":["# Reorganize the dataframe\n","# Note that rate and decision are not applicable because testimony is not at FOMC meeting\n","proc_testimony_df = reorganize_df(testimony_df, 'testimony')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nH1taGupppvt"},"source":["# Check the returned dataframe\n","proc_testimony_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzZ4ncaqppvt"},"source":["print(proc_testimony_df.shape)\n","sns.distplot(proc_testimony_df[\"word_count\"].values, bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6rhdnqBcppvt"},"source":["# Check records where speaker is null\n","proc_testimony_df['speaker'].isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzf_183kppvt"},"source":["# Remove sections having less than 50 words because those are unlikely to contain meaningful sentences.\n","proc_testimony_df = remove_short_section(proc_testimony_df, min_words=50)\n","proc_testimony_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9jOOAexppvt"},"source":["# Extract Chairperson's speech\n","tmp_list = []\n","for i, row in proc_testimony_df.iterrows():\n","    chairperson = get_chairperson(row['date'])\n","    if chairperson.lower().split()[-1] in row['speaker'].lower():\n","        row['speaker'] = chairperson\n","        tmp_list.append(list(row))\n","\n","col_names = proc_testimony_df.columns\n","testimony_chair_df = pd.DataFrame(data=tmp_list, columns=col_names)\n","testimony_chair_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4cTqXOmMppvt"},"source":["### Split contents to max 200 words"]},{"cell_type":"code","metadata":{"id":"-54bJDY6ppvt"},"source":["testimony_split_df = get_split_df(testimony_chair_df)\n","testimony_split_df.reset_index(drop=True, inplace=True)\n","print(testimony_split_df.shape)\n","testimony_split_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HcDZd7Z6ppvu"},"source":["### Filter out by keyword"]},{"cell_type":"code","metadata":{"id":"1LJqFpCAppvu"},"source":["# Keep sections having keywords and long enough\n","testimony_keyword_df = remove_short_nokeyword(testimony_chair_df)\n","testimony_keyword_df.reset_index(drop=True, inplace=True)\n","print(testimony_keyword_df.shape)\n","testimony_keyword_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgcJ15lKppvu"},"source":["# Drop text sections\n","testimony_chair_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","testimony_split_df.drop(columns=['text_sections', 'org_text'], inplace=True)\n","testimony_keyword_df.drop(columns=['text_sections', 'org_text'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZhiMMwgfppvu"},"source":["## Save the train data"]},{"cell_type":"code","metadata":{"id":"vwgm4x-eppvu"},"source":["text_no_split = pd.concat([proc_statement_df, \n","                           proc_minutes_df, \n","                           presconf_script_chair_day_df, \n","                           meeting_script_speaker_df, \n","                           speech_chair_df,\n","                           testimony_chair_df], sort=False)\n","text_no_split.reset_index(drop=True, inplace=True)\n","\n","text_split_200 = pd.concat([split_statement_df, \n","                            split_minutes_df, \n","                            presconf_script_split_df, \n","                            meeting_script_split_df, \n","                            speech_split_df, \n","                            testimony_split_df], sort=False)\n","text_split_200.reset_index(drop=True, inplace=True)\n","\n","text_keyword = pd.concat([keyword_statement_df,\n","                          keyword_minutes_df,\n","                          presconf_script_keyword_df,\n","                          meeting_script_keyword_df, \n","                          speech_keyword_df, \n","                          testimony_keyword_df], sort=False)\n","text_keyword.reset_index(drop=True, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oc5PKAiEppvu"},"source":["if IN_COLAB:\n","  def save_data(df, file_name, dir_name=preprocessed_dir):\n","    if not os.path.exists(dir_name):\n","      os.mkdir(dir_name)\n","    # Save results to a picke file\n","    file = open(dir_name + file_name + '.pickle', 'wb')\n","    pickle.dump(df, file)\n","    file.close()\n","    # Save results to a csv file\n","    df.to_csv(dir_name + file_name + '.csv', index=True)\n","else:\n","  def save_data(df, file_name, dir_name=preprocessed_dir):\n","    # Save results to a .picke file\n","    file = open(dir_name + file_name + '.pickle', 'wb')\n","    pickle.dump(df, file)\n","    file.close()\n","    # Save results to a .csv file\n","    df.to_csv(dir_name + file_name + '.csv', index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LwsOrV8tppvu"},"source":["save_data(text_no_split, 'text_no_split')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"skHo0LR1M3yH"},"source":["save_data(text_split_200, 'text_split_200')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2Rc6SPPM58Y"},"source":["save_data(text_keyword, 'text_keyword')"],"execution_count":null,"outputs":[]}]}